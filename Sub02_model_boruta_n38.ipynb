{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a7fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import numerapi, os, datetime,time,gc\n",
    "from numerapi import NumerAPI\n",
    "from utils import save_model, load_model, neutralize, get_biggest_change_features, validation_metrics, download_data, \\\n",
    "    load_model_config, save_model_config, get_time_series_cross_val_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187ece38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Get your API keys and model_id from https://numer.ai/submit\n",
    "public_id = \"TIFYUYGPJCFQZT4SBLNYIOZWQWIMC2EQ\"\n",
    "secret_key = \"QGLW6MHS7QIDPEELKVJ6DKUGBWHQMN7O3A2BCIV7CU4QKGTNVBZ7F5RRFF75M4DB\"\n",
    "model_1 = \"45b2b9e3-ed1b-4d82-bb2c-84f828b403fe\"\n",
    "model_2 = 'f624d92f-3965-4242-b069-dda40993fffa'\n",
    "model_3 ='b58e9477-feb6-4cd3-ae53-290326a41ecd'\n",
    "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a77a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "EXAMPLE_PREDS_COL = \"example_preds\"\n",
    "TARGET_COL = \"target\"\n",
    "ERA_COL = \"era\"\n",
    "PATH = \"E:/Anaconda3E/Numerai/massive_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7332500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering model selection loop.  This may take awhile.\n",
      "downloading training_data\n",
      "- Downloading numerai_training_data.parquet\\ Downloading numerai_training_data.parquet| Downloading numerai_training_data.parquet/ Downloading numerai_training_data.parquet- Downloading numerai_training_data.parquet\\ Downloading numerai_training_data.parquet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 15:05:36,608 INFO numerapi.utils: target file already exists\n",
      "2021-09-20 15:05:36,608 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Downloading numerai_training_data.parquet\n",
      "reading training data from local file\n",
      "entering time series cross validation loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "numerai_validation_data.parquet:  66%|██████▌   | 150M/228M [40:58<21:03, 61.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing split 1 out of 3\n",
      "getting feature correlations over time and identifying riskiest features\n",
      "entering model training loop for split 1\n",
      "model: model_target\n",
      "New features are available! Might want to retrain model model_target_split1cv3downsample20.\n",
      "predicting model_target\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_nomi_60\n",
      "New features are available! Might want to retrain model model_target_nomi_60_split1cv3downsample20.\n",
      "predicting model_target_nomi_60\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_jerome_20\n",
      "New features are available! Might want to retrain model model_target_jerome_20_split1cv3downsample20.\n",
      "predicting model_target_jerome_20\n",
      "doing neutralization to riskiest features\n",
      "creating ensembles\n",
      "doing split 2 out of 3\n",
      "getting feature correlations over time and identifying riskiest features\n",
      "entering model training loop for split 2\n",
      "model: model_target\n",
      "New features are available! Might want to retrain model model_target_split2cv3downsample20.\n",
      "predicting model_target\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_nomi_60\n",
      "New features are available! Might want to retrain model model_target_nomi_60_split2cv3downsample20.\n",
      "predicting model_target_nomi_60\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_jerome_20\n",
      "New features are available! Might want to retrain model model_target_jerome_20_split2cv3downsample20.\n",
      "predicting model_target_jerome_20\n",
      "doing neutralization to riskiest features\n",
      "creating ensembles\n",
      "doing split 3 out of 3\n",
      "getting feature correlations over time and identifying riskiest features\n",
      "entering model training loop for split 3\n",
      "model: model_target\n",
      "New features are available! Might want to retrain model model_target_split3cv3downsample20.\n",
      "predicting model_target\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_nomi_60\n",
      "New features are available! Might want to retrain model model_target_nomi_60_split3cv3downsample20.\n",
      "predicting model_target_nomi_60\n",
      "doing neutralization to riskiest features\n",
      "model: model_target_jerome_20\n",
      "New features are available! Might want to retrain model model_target_jerome_20_split3cv3downsample20.\n",
      "predicting model_target_jerome_20\n",
      "doing neutralization to riskiest features\n",
      "creating ensembles\n",
      "gathering validation metrics for out of sample training results\n",
      "|                                                  |      mean |   sharpe |\n",
      "|:-------------------------------------------------|----------:|---------:|\n",
      "| ensemble_not_neutral                             | 0.0459149 |  1.72076 |\n",
      "| preds_model_target                               | 0.0398028 |  1.64682 |\n",
      "| ensemble_all                                     | 0.0396923 |  1.63619 |\n",
      "| preds_model_target_nomi_60                       | 0.0418597 |  1.60583 |\n",
      "| preds_model_target_jerome_20                     | 0.040659  |  1.58296 |\n",
      "| ensemble_neutral_riskiest_50                     | 0.0308156 |  1.41755 |\n",
      "| preds_model_target_jerome_20_neutral_riskiest_50 | 0.0267188 |  1.29624 |\n",
      "| preds_model_target_neutral_riskiest_50           | 0.0254891 |  1.26079 |\n",
      "| preds_model_target_nomi_60_neutral_riskiest_50   | 0.026636  |  1.20612 |\n",
      "selecting model ensemble_not_neutral as our highest sharpe model in validation\n",
      "entering full training section\n",
      "getting feature correlations with target and identifying riskiest features\n",
      "saving model config for advanced_example_model\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# params we'll use to train all of our models.\n",
    "# Ideal params would be more like 20000, 0.001, 6, 2**6, 0.1, but this is slow enough as it is\n",
    "model_params = {\"n_estimators\": 2000,\n",
    "                \"learning_rate\": 0.01,\n",
    "                \"max_depth\": 5,\n",
    "                \"num_leaves\": 2 ** 5,\n",
    "                \"colsample_bytree\": 0.1}\n",
    "\n",
    "# the amount of downsampling we'll use to speed up cross validation and full train.\n",
    "# a value of 1 means no downsampling\n",
    "# a value of 10 means use every 10th row\n",
    "downsample_cross_val = 20\n",
    "downsample_full_train = 1\n",
    "\n",
    "# if model_selection_loop=True get OOS performance for training_data\n",
    "# and use that to select best model\n",
    "# if model_selection_loop=False, just predict on tournament data using existing models and model config\n",
    "model_selection_loop = True\n",
    "model_config_name = \"advanced_example_model\"\n",
    "\n",
    "napi = NumerAPI()\n",
    "\n",
    "current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament\n",
    "\n",
    "print(\"Entering model selection loop.  This may take awhile.\")\n",
    "if model_selection_loop:\n",
    "    model_config = {}\n",
    "    print('downloading training_data')\n",
    "    download_data(napi, 'numerai_training_data.parquet', 'numerai_training_data.parquet')\n",
    "\n",
    "    print(\"reading training data from local file\")\n",
    "    training_data = pd.read_parquet('numerai_training_data.parquet')\n",
    "\n",
    "    # keep track of some prediction columns\n",
    "    ensemble_cols = set()\n",
    "    pred_cols = set()\n",
    "\n",
    "    # pick some targets to use\n",
    "    possible_targets = [c for c in training_data.columns if c.startswith(\"target_\")]\n",
    "    # randomly pick a handful of targets\n",
    "    # this can be vastly improved\n",
    "    targets = [\"target\", \"target_nomi_60\", \"target_jerome_20\"]\n",
    "\n",
    "    # all the possible features to train on\n",
    "    #feature_cols = [c for c in training_data if c.startswith(\"feature_\")]\n",
    "    # https://forum.numer.ai/t/feature-selection-with-borutashap/4145\n",
    "    feature_cols = [\n",
    "                'feature_unwonted_trusted_fixative',\n",
    "                'feature_introvert_symphysial_assegai',\n",
    "                'feature_jerkwater_eustatic_electrocardiograph',\n",
    "                'feature_canalicular_peeling_lilienthal',\n",
    "                'feature_unvaried_social_bangkok',\n",
    "                'feature_crowning_frustrate_kampala',\n",
    "                'feature_store_apteral_isocheim',\n",
    "                'feature_haziest_lifelike_horseback',\n",
    "                'feature_grandmotherly_circumnavigable_homonymity',\n",
    "                'feature_assenting_darn_arthropod',\n",
    "                'feature_beery_somatologic_elimination',\n",
    "                'feature_cambial_bigoted_bacterioid',\n",
    "                'feature_unaired_operose_lactoprotein',\n",
    "                'feature_moralistic_heartier_typhoid',\n",
    "                'feature_twisty_adequate_minutia',\n",
    "                'feature_unsealed_suffixal_babar',\n",
    "                'feature_planned_superimposed_bend',\n",
    "                'feature_winsome_irreproachable_milkfish',\n",
    "                'feature_flintier_enslaved_borsch',\n",
    "                'feature_agile_unrespited_gaucho',\n",
    "                'feature_glare_factional_assessment',\n",
    "                'feature_slack_calefacient_tableau',\n",
    "                'feature_undivorced_unsatisfying_praetorium',\n",
    "                'feature_silver_handworked_scauper',\n",
    "                'feature_communicatory_unrecommended_velure',\n",
    "                'feature_stylistic_honduran_comprador',\n",
    "                'feature_travelled_semipermeable_perruquier',\n",
    "                'feature_bhutan_imagism_dolerite',\n",
    "                'feature_lofty_acceptable_challenge',\n",
    "                'feature_antichristian_slangiest_idyllist',\n",
    "                'feature_apomictical_motorized_vaporisation',\n",
    "                'feature_buxom_curtained_sienna',\n",
    "                'feature_gullable_sanguine_incongruity',\n",
    "                'feature_unforbidden_highbrow_kafir',\n",
    "                'feature_chuffier_analectic_conchiolin',\n",
    "    ]\n",
    "\n",
    "    \"\"\" do cross val to get out of sample training preds\"\"\"\n",
    "    cv = 3\n",
    "    train_test_zip = get_time_series_cross_val_splits(training_data, cv=cv, embargo=12)\n",
    "    # get out of sample training preds via embargoed time series cross validation\n",
    "    # optionally downsample training data to speed up this section.\n",
    "    print(\"entering time series cross validation loop\")\n",
    "    for split, train_test_split in enumerate(train_test_zip):\n",
    "        gc.collect()\n",
    "        print(f\"doing split {split+1} out of {cv}\")\n",
    "        train_split, test_split = train_test_split\n",
    "        train_split_index = training_data[ERA_COL].isin(train_split)\n",
    "        test_split_index = training_data[ERA_COL].isin(test_split)\n",
    "        downsampled_train_split_index = train_split_index[train_split_index].index[::downsample_cross_val]\n",
    "\n",
    "        # getting the per era correlation of each feature vs the primary target across the training split\n",
    "        print(\"getting feature correlations over time and identifying riskiest features\")\n",
    "        all_feature_corrs_split = training_data.loc[downsampled_train_split_index, :].groupby(ERA_COL).apply(\n",
    "            lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\n",
    "        # find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\n",
    "        # there are probably more clever ways to do this\n",
    "        riskiest_features_split = get_biggest_change_features(all_feature_corrs_split, 50)\n",
    "\n",
    "        print(f\"entering model training loop for split {split+1}\")\n",
    "        for target in targets:\n",
    "            model_name = f\"model_{target}\"\n",
    "            print(f\"model: {model_name}\")\n",
    "\n",
    "            # train a model on the training split (and save it for future use)\n",
    "            split_model_name = f\"model_{target}_split{split+1}cv{cv}downsample{downsample_cross_val}\"\n",
    "            split_model = load_model(split_model_name)\n",
    "            if not split_model:\n",
    "                print(f\"training model: {model_name}\")\n",
    "                split_model = LGBMRegressor(**model_params)\n",
    "                split_model.fit(training_data.loc[downsampled_train_split_index, feature_cols],\n",
    "                                training_data.loc[downsampled_train_split_index,\n",
    "                                                  [target]])\n",
    "                save_model(split_model, split_model_name)\n",
    "            # now we can predict on the test part of the split\n",
    "            model_expected_features = split_model.booster_.feature_name()\n",
    "            if set(model_expected_features) != set(feature_cols):\n",
    "                print(f\"New features are available! Might want to retrain model {split_model_name}.\")\n",
    "            print(f\"predicting {model_name}\")\n",
    "            training_data.loc[test_split_index, f\"preds_{model_name}\"] = \\\n",
    "                split_model.predict(training_data.loc[test_split_index, model_expected_features])\n",
    "\n",
    "            # do neutralization\n",
    "            print(\"doing neutralization to riskiest features\")\n",
    "            training_data.loc[test_split_index, f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
    "                df=training_data.loc[test_split_index, :],\n",
    "                columns=[f\"preds_{model_name}\"],\n",
    "                neutralizers=riskiest_features_split,\n",
    "                proportion=1.0, #defalut 0.8\n",
    "                normalize=True,\n",
    "                era_col=ERA_COL)[f\"preds_{model_name}\"]\n",
    "\n",
    "            # remember that we made all of these different pred columns\n",
    "            pred_cols.add(f\"preds_{model_name}\")\n",
    "            pred_cols.add(f\"preds_{model_name}_neutral_riskiest_50\")\n",
    "\n",
    "        print(\"creating ensembles\")\n",
    "        # ranking per era for all of our pred cols so we can combine safely on the same scales\n",
    "        training_data[list(pred_cols)] = training_data.groupby(ERA_COL).apply(\n",
    "            lambda d: d[list(pred_cols)].rank(pct=True))\n",
    "        # do ensembles\n",
    "        training_data[\"ensemble_neutral_riskiest_50\"] = sum(\n",
    "            [training_data[pred_col] for pred_col in pred_cols if pred_col.endswith(\"neutral_riskiest_50\")]).rank(\n",
    "            pct=True)\n",
    "        training_data[\"ensemble_not_neutral\"] = sum(\n",
    "            [training_data[pred_col] for pred_col in pred_cols if \"neutral\" not in pred_col]).rank(pct=True)\n",
    "        training_data[\"ensemble_all\"] = sum([training_data[pred_col] for pred_col in pred_cols]).rank(pct=True)\n",
    "\n",
    "        ensemble_cols.add(\"ensemble_neutral_riskiest_50\")\n",
    "        ensemble_cols.add(\"ensemble_not_neutral\")\n",
    "        ensemble_cols.add(\"ensemble_all\")\n",
    "\n",
    "    \"\"\" Now get some stats and pick our favorite model\"\"\"\n",
    "    print(\"gathering validation metrics for out of sample training results\")\n",
    "    all_model_cols = list(pred_cols) + list(ensemble_cols)\n",
    "    # use example_col preds_model_target as an estimates since no example preds provided for training\n",
    "    # fast_mode=True so that we skip some of the stats that are slower to calculate\n",
    "    training_stats = validation_metrics(training_data, all_model_cols, example_col=\"preds_model_target\",\n",
    "                                        fast_mode=True)\n",
    "    print(training_stats[[\"mean\", \"sharpe\"]].sort_values(by=\"sharpe\", ascending=False).to_markdown())\n",
    "\n",
    "    # pick the model that has the highest correlation sharpe\n",
    "    best_pred_col = training_stats.sort_values(by=\"sharpe\", ascending=False).head(1).index[0]\n",
    "    print(f\"selecting model {best_pred_col} as our highest sharpe model in validation\")\n",
    "\n",
    "    \"\"\" Now do a full train\"\"\"\n",
    "    print(\"entering full training section\")\n",
    "    # getting the per era correlation of each feature vs the target across all of training data\n",
    "    print(\"getting feature correlations with target and identifying riskiest features\")\n",
    "    all_feature_corrs = training_data.groupby(ERA_COL).apply(\n",
    "        lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\n",
    "    # find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\n",
    "    riskiest_features = get_biggest_change_features(all_feature_corrs, 50)\n",
    "\n",
    "    for target in targets:\n",
    "        gc.collect()\n",
    "        model_name = f\"model_{target}_downsample{downsample_full_train}\"\n",
    "        model = load_model(model_name)\n",
    "        if not model:\n",
    "            print(f\"training {model_name}\")\n",
    "            model = LGBMRegressor(**model_params)\n",
    "            # train on all of train, predict on val, predict on tournament\n",
    "            model.fit(training_data.iloc[::downsample_full_train].loc[:, feature_cols],\n",
    "                      training_data.iloc[::downsample_full_train][target])\n",
    "            save_model(model, model_name)\n",
    "        gc.collect()\n",
    "\n",
    "    model_config[\"feature_cols\"] = feature_cols\n",
    "    model_config[\"targets\"] = targets\n",
    "    model_config[\"best_pred_col\"] = best_pred_col\n",
    "    model_config[\"riskiest_features\"] = riskiest_features\n",
    "    print(f\"saving model config for {model_config_name}\")\n",
    "    save_model_config(model_config, model_config_name)\n",
    "else:\n",
    "    # load model config from previous model selection loop\n",
    "    print(f\"loading model config for {model_config_name}\")\n",
    "    model_config = load_model_config(model_config_name)\n",
    "    feature_cols = model_config[\"feature_cols\"]\n",
    "    targets = model_config[\"targets\"]\n",
    "    best_pred_col = model_config[\"best_pred_col\"]\n",
    "    riskiest_features = model_config[\"riskiest_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9b863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading tournament_data\n",
      "- Downloading numerai_tournament_data_282.parquet\\ Downloading numerai_tournament_data_282.parquet| Downloading numerai_tournament_data_282.parquet/ Downloading numerai_tournament_data_282.parquet- Downloading numerai_tournament_data_282.parquet\\ Downloading numerai_tournament_data_282.parquet| Downloading numerai_tournament_data_282.parquet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 15:17:21,066 INFO numerapi.utils: target file already exists\n",
      "2021-09-20 15:17:21,067 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Downloading numerai_tournament_data_282.parquet\n",
      "downloading validation_data\n",
      "- Downloading numerai_validation_data.parquet\\ Downloading numerai_validation_data.parquet| Downloading numerai_validation_data.parquet/ Downloading numerai_validation_data.parquet- Downloading numerai_validation_data.parquet\\ Downloading numerai_validation_data.parquet| Downloading numerai_validation_data.parquet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 15:17:21,853 INFO numerapi.utils: target file already exists\n",
      "2021-09-20 15:17:21,854 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Downloading numerai_validation_data.parquet\n",
      "downloading example_predictions\n",
      "- Downloading example_predictions_282.parquet\\ Downloading example_predictions_282.parquet| Downloading example_predictions_282.parquet/ Downloading example_predictions_282.parquet- Downloading example_predictions_282.parquet\\ Downloading example_predictions_282.parquet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 15:17:22,677 INFO numerapi.utils: target file already exists\n",
      "2021-09-20 15:17:22,677 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Downloading example_predictions_282.parquet\n",
      "downloading example_validation_predictions\n",
      "- Downloading example_validation_predictions.parquet\\ Downloading example_validation_predictions.parquet| Downloading example_validation_predictions.parquet/ Downloading example_validation_predictions.parquet- Downloading example_validation_predictions.parquet\\ Downloading example_validation_predictions.parquet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 15:17:23,376 INFO numerapi.utils: target file already exists\n",
      "2021-09-20 15:17:23,377 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v Downloading example_validation_predictions.parquet\n",
      "reading tournament_data\n",
      "reading validation_data\n",
      "reading example_predictions\n",
      "reading example_validaton_predictions\n",
      "checking for nans in the tournament data\n",
      "No nans in the features this week!\n",
      "loading model_target_downsample1\n",
      "New features are available! Might want to retrain model model_target_downsample1.\n",
      "predicting tournament and validation for model_target_downsample1\n",
      "neutralizing to riskiest_50 for validation and tournament\n",
      "loading model_target_nomi_60_downsample1\n",
      "New features are available! Might want to retrain model model_target_nomi_60_downsample1.\n",
      "predicting tournament and validation for model_target_nomi_60_downsample1\n",
      "neutralizing to riskiest_50 for validation and tournament\n",
      "loading model_target_jerome_20_downsample1\n",
      "New features are available! Might want to retrain model model_target_jerome_20_downsample1.\n",
      "predicting tournament and validation for model_target_jerome_20_downsample1\n",
      "neutralizing to riskiest_50 for validation and tournament\n",
      "creating ensembles for tournament and validation\n",
      "getting final validation stats\n",
      "|                      |      mean |       std |   sharpe |   max_drawdown |     apy |   max_feature_exposure |   feature_neutral_mean |   tb200_mean |   tb200_std |   tb200_sharpe |   mmc_mean |   corr_plus_mmc_sharpe |   corr_with_example_preds |\n",
      "|:---------------------|----------:|----------:|---------:|---------------:|--------:|-----------------------:|-----------------------:|-------------:|------------:|---------------:|-----------:|-----------------------:|--------------------------:|\n",
      "| ensemble_not_neutral | 0.0259979 | 0.0338712 | 0.767552 |      -0.169752 | 242.464 |               0.435624 |              0.0187038 |    0.0604419 |   0.0736745 |       0.767552 | 0.00557627 |               0.670869 |                  0.734186 |\n",
      "\r"
     ]
    }
   ],
   "source": [
    "\"\"\" Things that we always do even if we've already trained \"\"\"\n",
    "gc.collect()\n",
    "print(\"downloading tournament_data\")\n",
    "download_data(napi, 'numerai_tournament_data.parquet', f'numerai_tournament_data_{current_round}.parquet')\n",
    "print(\"downloading validation_data\")\n",
    "download_data(napi, 'numerai_validation_data.parquet', 'numerai_validation_data.parquet')\n",
    "print(\"downloading example_predictions\")\n",
    "download_data(napi, 'example_predictions.parquet', f'example_predictions_{current_round}.parquet')\n",
    "print(\"downloading example_validation_predictions\")\n",
    "download_data(napi, 'example_validation_predictions.parquet', f'example_validation_predictions.parquet')\n",
    "\n",
    "print(\"reading tournament_data\")\n",
    "tournament_data = pd.read_parquet(f'numerai_tournament_data_{current_round}.parquet')\n",
    "print(\"reading validation_data\")\n",
    "validation_data = pd.read_parquet('numerai_validation_data.parquet')\n",
    "print(\"reading example_predictions\")\n",
    "example_preds = pd.read_parquet(f'example_predictions_{current_round}.parquet')\n",
    "print(\"reading example_validaton_predictions\")\n",
    "validation_example_preds = pd.read_parquet('example_validation_predictions.parquet')\n",
    "# set the example predictions\n",
    "validation_data[EXAMPLE_PREDS_COL] = validation_example_preds[\"prediction\"]\n",
    "\n",
    "# check for nans and fill nans\n",
    "print(\"checking for nans in the tournament data\")\n",
    "if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\n",
    "    cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\n",
    "    total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\n",
    "    print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\n",
    "    print(f\"out of {total_rows} total rows\")\n",
    "    print(f\"filling nans with 0.5\")\n",
    "    tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\n",
    "else:\n",
    "    print(\"No nans in the features this week!\")\n",
    "\n",
    "\n",
    "pred_cols = set()\n",
    "ensemble_cols = set()\n",
    "for target in targets:\n",
    "    gc.collect()\n",
    "    model_name = f\"model_{target}_downsample{downsample_full_train}\"\n",
    "    print(f\"loading {model_name}\")\n",
    "    model = load_model(model_name)\n",
    "    if not model:\n",
    "        raise ValueError(f\"{model_name} is not trained yet!\")\n",
    "\n",
    "    model_expected_features = model.booster_.feature_name()\n",
    "    if set(model_expected_features) != set(feature_cols):\n",
    "        print(f\"New features are available! Might want to retrain model {model_name}.\")\n",
    "    print(f\"predicting tournament and validation for {model_name}\")\n",
    "    validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(validation_data.loc[:, model_expected_features])\n",
    "    tournament_data.loc[:, f\"preds_{model_name}\"] = model.predict(tournament_data.loc[:, model_expected_features])\n",
    "\n",
    "    # do different neutralizations\n",
    "    # neutralize our predictions to the riskiest features only\n",
    "    print(\"neutralizing to riskiest_50 for validation and tournament\")\n",
    "    validation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=validation_data,\n",
    "                                                                            columns=[f\"preds_{model_name}\"],\n",
    "                                                                            neutralizers=riskiest_features,\n",
    "                                                                            proportion=1.0,\n",
    "                                                                            normalize=True,\n",
    "                                                                            era_col=ERA_COL)[f\"preds_{model_name}\"]\n",
    "    tournament_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=tournament_data,\n",
    "                                                                            columns=[f\"preds_{model_name}\"],\n",
    "                                                                            neutralizers=riskiest_features,\n",
    "                                                                            proportion=1.0,\n",
    "                                                                            normalize=True,\n",
    "                                                                            era_col=ERA_COL)[f\"preds_{model_name}\"]\n",
    "\n",
    "    pred_cols.add(f\"preds_{model_name}\")\n",
    "    pred_cols.add(f\"preds_{model_name}_neutral_riskiest_50\")\n",
    "\n",
    "\n",
    "# rank per era for each prediction column so that we can combine safely\n",
    "validation_data[list(pred_cols)] = validation_data.groupby(ERA_COL).apply(lambda d: d[list(pred_cols)].rank(pct=True))\n",
    "tournament_data[list(pred_cols)] = tournament_data.groupby(ERA_COL).apply(lambda d: d[list(pred_cols)].rank(pct=True))\n",
    "# make ensembles for val and tournament\n",
    "print('creating ensembles for tournament and validation')\n",
    "validation_data[\"ensemble_neutral_riskiest_50\"] = sum(\n",
    "    [validation_data[pred_col] for pred_col in pred_cols if pred_col.endswith(\"neutral_riskiest_50\")]).rank(\n",
    "    pct=True)\n",
    "tournament_data[\"ensemble_neutral_riskiest_50\"] = sum(\n",
    "    [tournament_data[pred_col] for pred_col in pred_cols if pred_col.endswith(\"neutral_riskiest_50\")]).rank(\n",
    "    pct=True)\n",
    "ensemble_cols.add(\"ensemble_neutral_riskiest_50\")\n",
    "\n",
    "validation_data[\"ensemble_not_neutral\"] = sum(\n",
    "    [validation_data[pred_col] for pred_col in pred_cols if \"neutral\" not in pred_col]).rank(pct=True)\n",
    "tournament_data[\"ensemble_not_neutral\"] = sum(\n",
    "    [tournament_data[pred_col] for pred_col in pred_cols if \"neutral\" not in pred_col]).rank(pct=True)\n",
    "ensemble_cols.add(\"ensemble_not_neutral\")\n",
    "\n",
    "validation_data[\"ensemble_all\"] = sum([validation_data[pred_col] for pred_col in pred_cols]).rank(pct=True)\n",
    "tournament_data[\"ensemble_all\"] = sum([tournament_data[pred_col] for pred_col in pred_cols]).rank(pct=True)\n",
    "\n",
    "ensemble_cols.add(\"ensemble_neutral_riskiest_50\")\n",
    "ensemble_cols.add(\"ensemble_not_neutral\")\n",
    "ensemble_cols.add(\"ensemble_all\")\n",
    "\n",
    "gc.collect()\n",
    "print(\"getting final validation stats\")\n",
    "# get our final validation stats for our chosen model\n",
    "validation_stats = validation_metrics(validation_data, [best_pred_col], example_col=EXAMPLE_PREDS_COL,\n",
    "                                      fast_mode=False)\n",
    "print(validation_stats.to_markdown())\n",
    "\n",
    "# rename best model to prediction and rank from 0 to 1 to meet diagnostic/submission file requirements\n",
    "validation_data[\"prediction\"] = validation_data[best_pred_col].rank(pct=True)\n",
    "tournament_data[\"prediction\"] = tournament_data[best_pred_col].rank(pct=True)\n",
    "#validation_data[\"prediction\"].to_csv(f\"prediction_files/validation_predictions_{current_round}.csv\", index=True)\n",
    "tournament_data[\"prediction\"].to_csv(PATH+ \"/prediction_files/tournament_pred_\"+\"n\"+str(len(feature_cols))+\\\n",
    "                                     \"_round\"+str(current_round)+\".csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff85d9",
   "metadata": {},
   "source": [
    "# numeracli をアップデートしたらErrorでないかもしれないがLegacyができなくなるかも。それまではマニュアルアップデート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cabd76a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 14:39:54,397 INFO numerapi.base_api: uploading predictions...\n",
      "2021-09-20 14:40:12,088 ERROR numerapi.base_api: Test prediction ids do not match. IDs must match current tournament data exactly, including ordering. Make sure you are using the latest tournament data.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Test prediction ids do not match. IDs must match current tournament data exactly, including ordering. Make sure you are using the latest tournament data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9837e2d603f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#submission_id = napi.upload_predictions(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#\"./sub/predictions_xg_std_n11_seed_ave.csv\", model_id= model_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m submission_id = napi.upload_predictions(\n\u001b[0m\u001b[0;32m      4\u001b[0m \"./prediction_files/tournament_predictions_\"+str(current_round)+\".csv\", model_id= model_2)\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#submission_id = napi.upload_predictions(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_fastai\\lib\\site-packages\\numerapi\\numerapi.py\u001b[0m in \u001b[0;36mupload_predictions\u001b[1;34m(self, file_path, tournament, model_id, df, version)\u001b[0m\n\u001b[0;32m    631\u001b[0m                      \u001b[1;34m'modelId'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                      'triggerId': os.getenv('TRIGGER_ID', None)}\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[0mcreate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthorization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[0msubmission_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_submission'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msubmission_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_fastai\\lib\\site-packages\\numerapi\\base_api.py\u001b[0m in \u001b[0;36mraw_query\u001b[1;34m(self, query, variables, authorization)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_call_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# fail!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Test prediction ids do not match. IDs must match current tournament data exactly, including ordering. Make sure you are using the latest tournament data."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "submission_id = napi.upload_predictions(\n",
    "PATH+ \"/prediction_files/tournament_pred_\"+\"n\"+str(len(feature_cols))+\\\n",
    "                                     \"_round\"+str(current_round)+\".csv\", model_id= model_1,version=2)\n",
    "#submission_id = napi.upload_predictions(\n",
    "#PATH+ \"/prediction_files/tournament_pred_\"+\"n\"+str(len(feature_cols))+\\\n",
    "#                                     \"_round\"+str(current_round)+\".csv\", model_id= model_2,version=2)\n",
    "#submission_id = napi.upload_predictions(\n",
    "#PATH+ \"/prediction_files/tournament_pred_\"+\"n\"+str(len(feature_cols))+\\\n",
    "#                                     \"_round\"+str(current_round)+\".csv\", model_id= model_3,version=2)\n",
    "\n",
    "print('uploaded prediction to KMTK49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e881a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
